{
  "componentName": "TrtisDetection",
  "componentVersion": "5.0.0",
  "middlewareVersion": "5.0.0",
  "sourceLanguage": "c++",
  "batchLibrary": "${MPF_HOME}/plugins/TrtisDetection/lib/libmpfTrtisDetection.so",
  "environmentVariables": [
    {
      "name": "LD_LIBRARY_PATH",
      "value": "${MPF_HOME}/plugins/TrtisDetection/lib:${LD_LIBRARY_PATH}"
    }
  ],
  "algorithm": {
    "name": "TRTIS",
    "description": "Returns a model-specific inference result from an input image.",
    "actionType": "DETECTION",
    "requiresCollection": {
      "states": []
    },
    "providesCollection": {
      "states": [
        "DETECTION",
        "DETECTION_CLASS",
        "DETECTION_CLASS_TRTIS"
      ],
      "properties": [
        {
          "name": "TRTIS_SERVER",
          "description": "The DNS name or IP address and GRPC port of an NVIDIA TensorRT Inference Server (TRTIS) which is setup to server the requested model' inferences. If the value is set to the empty string \"\", the component will instead use the environment variable for `TRTIS_SERVER`, if it is available.",
          "type": "STRING",
          "defaultValue": ""
        },
        {
          "name": "MODEL_NAME",
          "description": "The model on the inference server to be used for inferencing. 'ip_irv2_coco' is provided by default. NOTE: Currently, only 'ip_irv2_coco' is supported.",
          "type": "STRING",
          "defaultValue": "ip_irv2_coco"
        },
        {
          "name": "MODEL_VERSION",
          "description": "The version number of the inference server model. '-1' means the latest version available on the server.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "MAX_INFER_CONCURRENCY",
          "description": "Maximum number of inference requests that will be sent to the server concurrently for video inferencing. This allows time overlapping of inferencing on the server and reading/processing video frames on the client.",
          "type": "INT",
          "defaultValue": "5"
        },
        {
          "name": "USER_FEATURE_ENABLE",
          "description": "'ip_irv2_coco' model specific: Whether or not to generate similarity feature detections for user-specified bounding box. All of these features have a confidence of -1.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "USER_FEATURE_X_LEFT_UPPER",
          "description": "'ip_irv2_coco' model specific: Upper left hand user bounding box pixel x-coordinate.",
          "type": "INT",
          "defaultValue": "0"
        },
        {
          "name": "USER_FEATURE_Y_LEFT_UPPER",
          "description": "'ip_irv2_coco' model specific: Upper left hand user bounding box pixel y-coordinate.",
          "type": "INT",
          "defaultValue": "0"
        },
        {
          "name": "USER_FEATURE_WIDTH",
          "description": "'ip_irv2_coco' model specific: Width of user bounding box in pixels, defaults to image/frame width when value <= 0.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "USER_FEATURE_HEIGHT",
          "description": "'ip_irv2_coco' model specific: Height of user bounding box in pixels, defaults to image/frame height when value <= 0.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "FRAME_FEATURE_ENABLE",
          "description": "'ip_irv2_coco' model specific: Whether or not to generate a similarity feature for the entire image/each frame.  This feature is a size weighted average of all other features in the image/frame. All of these features have a confidence of -1.",
          "type": "BOOLEAN",
          "defaultValue": "true"
        },
        {
          "name": "CLASS_FEATURE_ENABLE",
          "description": "'ip_irv2_coco' model specific: Whether or not to generate similarity features for any detected COCO-class objects.",
          "type": "BOOLEAN",
          "defaultValue": "true"
        },
        {
          "name": "EXTRA_FEATURE_ENABLE",
          "description": "'ip_irv2_coco' model specific: Whether or not to generate similarity features for any candidate object regions that could not be classified as COCO objects.",
          "type": "BOOLEAN",
          "defaultValue": "true"
        },
        {
          "name": "CLIENT_PRESCALING_ENABLE",
          "description": "'ip_irv2_coco' model specific: Whether to scale images/frames on the client or inference server to approximately [1024 x 600] as required by this model.",
          "type": "BOOLEAN",
          "defaultValue": "true"
        },
        {
          "name": "RECOGNITION_ENROLL_ENABLE",
          "description": "NOTE: Not implemented yet. 'ip_irv2_coco' model specific: Whether to send generated similarity features to recognition frame work for enrollment in a gallery.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "CLASS_CONFIDENCE_THRESHOLD",
          "description": "'ip_irv2_coco' model specific: Specifies threshold for object region detections that can be classified as COCO objects.",
          "type": "DOUBLE",
          "defaultValue": "0.0"
        },
        {
          "name": "EXTRA_CONFIDENCE_THRESHOLD",
          "description": "'ip_irv2_coco' model specific: Threshold for object region detections that could not be classified as COCO objects.  Note, the confidence scores of these extra detections is generally close to 0.",
          "type": "DOUBLE",
          "defaultValue": "0.0"
        },
        {
          "name": "TRACK_MAX_FEATURE_GAP",
          "description": "'ip_irv2_coco' model specific: Maximum gap in similarity feature space (i.e. cos-distance) for objects to be considered to be in the same track.",
          "type": "DOUBLE",
          "defaultValue": "0.25"
        },
        {
          "name": "TRACK_MAX_FRAME_GAP",
          "description": "'ip_irv2_coco' model specific: Maximum gap in frames (i.e. time) for objects to be considered to be in the same track.",
          "type": "INT",
          "defaultValue": "30"
        },
        {
          "name": "TRACK_MAX_SPACE_GAP",
          "description": "'ip_irv2_coco' model specific: Maximum gap in diagonal-normalized pixel space for objects to be considered to be in the same track. Normalization is performed via the image/frame diagonal (sqrt[width*width + height*height])",
          "type": "DOUBLE",
          "defaultValue": "0.3"
        }
      ]
    }
  },
  "actions": [
    {
      "name": "TRTIS IP_IRV2_COCO DETECTION ACTION",
      "description": "Performs TRTIS detection using the 'ip_irv2_coco' model.",
      "algorithm": "TRTIS",
      "properties": [
        {
          "name": "MODEL_NAME",
          "value": "ip_irv2_coco"
        },
        {
          "name": "MODEL_VERSION",
          "value": "-1"
        }
      ]
    }
  ],
  "tasks": [
    {
      "name": "TRTIS IP_IRV2_COCO DETECTION TASK",
      "description": "Performs TRTIS detection using the 'ip_irv2_coco' model.",
      "actions": [
        "TRTIS IP_IRV2_COCO DETECTION ACTION"
      ]
    }
  ],
  "pipelines": [
    {
      "name": "TRTIS IP_IRV2_COCO DETECTION PIPELINE",
      "description": "Performs TRTIS detection using the 'ip_irv2_coco' model.",
      "tasks": [
        "TRTIS IP_IRV2_COCO DETECTION TASK"
      ]
    },
    {
      "name": "TRTIS IP_IRV2_COCO DETECTION (WITH MARKUP) PIPELINE",
      "description": "Performs TRTIS detection using the 'ip_irv2_coco' model and produces markup.",
      "tasks": [
        "TRTIS IP_IRV2_COCO DETECTION TASK",
        "OCV GENERIC MARKUP TASK"
      ]
    }
  ]
}
