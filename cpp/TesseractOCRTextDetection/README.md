# Overview

This repository contains source code and model data for the OpenMPF Tesseract
OCR text detection component.

The component extracts text found in an image, reported as a single track detection.
PDF documents can also be processed with one track detection per page. The first page
corresponds to the detection property PAGE_NUM = 1. For debugging purposes, images converted
from documents are stored in a temporary job directory under
`plugin/TesseractOCR/tmp-[job-id]-[random tag]`. This directory is removed when the job completes successfully.

Please refer to https://imagemagick.org/script/formats.php for support of other document file formats.

Users may set the language of each track using the TESSERACT_LANGUAGE parameter
as well as adjust image preprocessing settings for text extraction.

For processing English text, users can enable filters (THRS_FILTER, HIST_FILTER)
to eliminate gibberish detections from a given scene. All text extracted from
an image can also be tagged using regex and keyword tags in a given json file.
For keyword tagging, users can provide either words or phrases
(ex. "bank-tag: [money, bank of america, etc.]"). Phrases must contain
words separated by white-space. For more complex pattern matching, use regex tags
instead. Both forms of tagging are case-insensitive.


By default the json tagging file is located in the config folder as text-tags.json,
however users can provide an alternate full path to a tagging file of their choice.
English and foreign text tags following UTF-8 encoding are supported.


Language models supported by Tesseract are stored by default in
`$MPF_HOME/plugins/TesseractOCRTextDetection/tessdata` directory and script models
are stored in `tessdata/script`. Users can set a new tessdata directory by
modifying the MODELS_DIR_PATH job property. Once set, the component will look for tessdata files in
`[MODELS_DIR_PATH]/TesseractOCRTextDetection/tessdata`.

By default, the component will first check for models in the MODELS_DIR_PATH followed
by the default tessdata path. Please ensure that any language models that run together are stored together in the same
directory (i.e. while running "eng+bul", both eng.traineddata and bul.traineddata should be stored together in at least
one specified directory, while running "eng,bul" the models can be stored separately).

Additional tessdata models can then be added to the specified
tessdata folder to expand supported languages and scripts.

Each language module follows ISO 639-2 designations, with character variations
of a language (ex. uzb_cyrl) also supported. Users must enter the same designation
to enable the corresponding language detection (ex. TESSERACT_LANGUAGE = "deu"
for German text). Users will be warned when a given language is not supported when the
corresponding language module cannot be located in this directory.

Each script module is contained within the `tessdata/script` directory with the
first letter of its type capitalized (ex. `tessdata/script/Latin.traineddata`). Users will need to
specify the `script/` path followed by the full name of the script being processed.
(ex. TESSERACT_LANGUAGE='script/Latin' will enable Latin script text extraction).

Users can set ENABLE_OSD_AUTOMATION to true to enable automatic orientation and script detection:
•	An additional 7 parameters are reported in corresponding OCR tracks:
o	PRIMARY_SCRIPT, SECONDARY_SCRIPTS, and ROTATION (0, 90, 180, and 270 degrees counterclockwise) of text in an image.
o	For primary and secondary detected scripts, raw scores for each prediction are stored
inside of PRIMARY_SCRIPT_SCORE and SECONDARY_SCRIPT_SCORES.
o	For the primary script, PRIMARY_SCRIPT_CONFIDENCE, is also generated by Tesseract, specifying the relative confidence
of the primary script score against the second top detected script score.
o	Similarly, ROTATION_CONFIDENCE represents the relative confidence of the top text orientation prediction score against the
second best text orientation prediction score. Raw text orientation scores are excluded from the report as the individual values are not
normalized (large non-positive values that provide little insight into prediction confidence, unlike individual script scores).
•	If the detected text orientation is >= MIN_OSD_ROTATION_CONFIDENCE threshold, then the frame will automatically be rotated 0, 90, 180, or 270 degrees before performing OCR. If the threshold is not exceeded, then OCR is performed on the default orientation (0 degree rotation).
•	If the detected script confidence is >= the MIN_OSD_SCRIPT_CONFIDENCE threshold, and script score is >= the MIN_OSD_SCRIPT_SCORE threshold, then OCR will be performed for the script and the TESSERACT_LANGUAGE setting will be ignored. If either threshold is not exceeded, then OCR is performed using the TESSERACT_LANGUAGE setting.
•	If OSD detects multiple scripts, and MAX_SCRIPTS is >= 2, then OCR will be performed on each detected script given these rules:
o	Each detected script must be >= the MIN_OSD_SCRIPT_CONFIDENCE and MIN_OSD_SCRIPT_SCORE thresholds.
o	The detected script with the highest score is considered the primary script. The others are considered secondary scripts. Secondary scripts must have scores are >= the MIN_OSD_SECONDARY_SCRIPT_THRESHOLD, which is a % applied primary script score. For example, if MIN_OSD_SECONDARY_SCRIPT_THRESHOLD=80%, then the secondary scripts must have scores that are at least 80% of the primary script score.
o	Note that if the number of detected scripts exceeds the MAX_SCRIPTS setting, then only the scripts with the highest scores are considered.

There are two options to run multiple user-specified languages/scripts. Users can separate each
specified language and script using the '+' delimiter to run multiple models
together in one track and ',' to run them as separate tracks. Delimiters
can also be combined for separate multilingual tracks. Lastly, users can set MAX_TEXT_TRACKS to limit the number of
reported OCR tracks so that only the tracks with the highest scores are reported.
Note that if this is set lower than the number of scripts detected by OSD, then the OCR tracks for the scripts with the
lowest scores will not be reported.

Please note that the order of the specified language matters. Languages specified first
will have priority (ex. 'eng+deu', English language model will run first and its results will have
priority over German language model).

Example 1: 'eng+deu' = run English, German together as one track detection.
Example 2: 'eng,deu+fra'= run English as the first track and German + French
as the second track.
Example 3: 'fra,script/Latin'= run French as the first track, and Latin script as
the second track.

By default this component contains language model files for Bulgarian (bul),
Chinese - Simplified (chi_sim), German (deu), English (eng), French (fra), Pashto (pus),
Russian (rus), and Spanish (spa) as well as the script model file for Latin (script/Latin).
Note the osd language file (osd.traindata) is for extraction of script orientation rather than language.
Users may download and load in additional language models from https://github.com/tesseract-ocr/tessdata,
stored in the component's `tessdata` directory.

Users may also set Page Segmentation and OCR Engine modes by adjusting TESSERACT_PSM and
TESSERACT_OEM respectively. Please be warned that running TESSERACT_OEM with values 2 or 3 can occasionally
lead to conflicts between the legacy and LSTM engines. Therefore, the default OEM has been set to use the LSTM engine
until this issue is resolved.

The parameter options for the OCR Engine mode are:

TESSERACT_OEM Value| Description
------------- | -------------
0  |  Legacy engine only.
1  |  Neural nets LSTM engine only.
2  |  Legacy + LSTM engines.
3  |  Default, based on what is available.


The parameter options for the Page Segmentation mode are:

TESSERACT_PSM Value| Description
------------- | -------------
0  |  Orientation and script detection (OSD) only.
1  |  Automatic page segmentation with OSD.
2  |  Automatic page segmentation, but no OSD, or OCR.
3  |  Fully automatic page segmentation, but no OSD. (Default)
4  |  Assume a single column of text of variable sizes.
5  |  Assume a single uniform block of vertically aligned text.
6  |  Assume a single uniform block of text.
7  |  Treat the image as a single text line.
8  |  Treat the image as a single word.
9  |  Treat the image as a single word in a circle.
10 |  Treat the image as a single character.
11 |  Sparse text. Find as much text as possible in no particular order.
12 |  Sparse text with OSD.
13 |  Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.

For more details please consult the Tesseract command line usage documentation
(https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage).
