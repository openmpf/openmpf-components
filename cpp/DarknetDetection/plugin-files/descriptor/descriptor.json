{
  "componentName": "DarknetDetection",
  "componentVersion": "2.1.0",
  "middlewareVersion": "2.1.0",
  "sourceLanguage": "c++",
  "batchLibrary": "${MPF_HOME}/plugins/DarknetDetection/lib/libmpfDarknetDetection.so",
  "environmentVariables": [
    {
      "name": "LD_LIBRARY_PATH",
      "value": "${MPF_HOME}/plugins/DarknetDetection/lib:${LD_LIBRARY_PATH}"
    }
  ],
  "algorithm": {
    "name": "DARKNET",
    "description": "Runs Darknet models.",
    "actionType": "DETECTION",
    "requiresCollection": {
      "states": []
    },
    "providesCollection": {
      "states": [
        "DETECTION",
        "DETECTION_CLASS",
        "DETECTION_CLASS_DARKNET"
      ],
      "properties": [
        {
          "name": "FEED_FORWARD_TYPE",
          "description": "Applies to images and videos. The type of feed-forward behavior. Controls how this algorithm will make use of the tracks generated in the previous pipeline stage. If this algorithm is used in the first pipeline stage then this property has no effect. Instead, the default segmenting behavior is used, where tracks from the previous stage are used to generate segments based on the TARGET_SEGMENT_LENGTH and MIN_SEGMENT_LENGTH properties. Can be set to “NONE”, “FRAME”, “SUPERSET_REGION”, or “REGION”. If set to “NONE”, the default segmenting behavior is used. If set to “FRAME”, “SUPERSET_REGION”, or “REGION” then the segment length properties are ignored and instead this algorithm will process one segment per track generated in the previous stage. If set to “FRAME”, then this algorithm will ignore the regions associated with previous detections and instead process the entire frame associated with each of those detections. If set to “SUPERSET_REGION”, then this algorithm will generate a superset region for each of the previous tracks – a bounding box of constant size and position that encloses all of the track’s detection regions. This algorithm will only process the data within the superset region. If set to “REGION”, then this algorithm will use the regions associated with previous detections, which may vary in size and position from frame to frame.",
          "type": "STRING",
          "defaultValue": "NONE"
        },
        {
          "name": "FEED_FORWARD_TOP_CONFIDENCE_COUNT",
          "description": "Only applies if FEED_FORWARD_TYPE is set to a value other than “NONE”. If set to a value <= 0, then for each track generated in the previous pipeline stage, this algorithm will process the frame associated with each detection in that track, ignoring frames that don’t have detections. If FEED_FORWARD_TYPE is set to “FRAME”, then the entire frame is processed. If FEED_FORWARD_TYPE is set to “SUPERSET_REGION”, then only the superset region for those frames is processed. If FEED_FORWARD_TYPE is set to “REGION”, then the specific detection region for each frame is processed. If this property is set to “1” then only the exemplar frame for each of the previous tracks is processed. If this property is set to a value > 1, say 5, then each of the detections in the previous track are sorted by confidence and this algorithm will only process the frames associated with the top 5 detections with the highest confidence. For detections with the same confidence values, it will select those with a lower frame index. If the track contains less than 5 detections, then all of the available detections are used. In practice, setting this property to a value > 1 has no effect on image and audio jobs because each track only contains one detection.",
          "type": "INT",
          "defaultValue": "0"
        },
        {
          "name": "USE_KEY_FRAMES",
          "description": "When true the component will only look at key frames (I-frames) from the input video. Can be used in conjunction with FRAME_INTERVAL. For example, when USE_KEY_FRAMES is true, and FRAME_INTERVAL is set to \"2\", then every other key frame will be processed.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "FRAME_INTERVAL",
          "description": "Controls whether the component performs detection on every frame in the video segment, or skips some frames at a regular interval. Must be set to a value >= 0. If set to 0 or 1, a frame interval of 1 will be used, meaning that detection is performed on every frame. If set to N > 1, every N-1 frames will be skipped. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.sampling.interval"
        },
        {
          "name": "FRAME_RATE_CAP",
          "description": "The threshold on the maximum number of frames to process in the video segment within one second of the native video time. If set to a value > 0, then an internal frame interval value is calculated as max(1, floor(mediaNativeFPS / FRAME_RATE_CAP)) and the FRAME_INTERVAL property is not used. To disable, set to a value <= 0. When disabled, the FRAME_INTERVAL property is used, if valid. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.frame.rate.cap"
        },
        {
          "name": "CONFIDENCE_THRESHOLD",
          "description": "The confidence threshold for returning a classification result. No classifications lower than this threshold will be returned, even if that means returning fewer classifications than the number of classifications requested. The value must be greater than or equal to 0.0.",
          "type": "DOUBLE",
          "defaultValue": "0.5"
        },
        {
          "name": "MIN_GAP_BETWEEN_SEGMENTS",
          "description": "In the context of videos, the minimum number of frames between segments which are not adjacent. Value must be greater than or equal to 1. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.segment.minimum.gap"
        },
        {
          "name": "TARGET_SEGMENT_LENGTH",
          "description": "In the context of videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.segment.target.length"
        },
        {
          "name": "MIN_SEGMENT_LENGTH",
          "description": "In the context of videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.segment.minimum.length"
        },
        {
          "name": "MERGE_TRACKS",
          "description": "In the context of videos, when set to true, attempt to merge tracks spanning segment boundaries. Default value is defined by the OpenMPF properties file.",
          "type": "BOOLEAN",
          "propertiesKey": "detection.track.merging.enabled"
        },
        {
          "name": "MIN_GAP_BETWEEN_TRACKS",
          "description": "In the context of videos, similar tracks with less than this number of frames between them will be merged into a single track. If MERGE_TRACKS is false, this has no effect. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.track.min.gap"
        },
        {
          "name": "MIN_TRACK_LENGTH",
          "description": "In the context of videos, defines the minimum track length in frames. Tracks shorter than this minimum length will be silently discarded. Default value is defined by the OpenMPF properties file.",
          "type": "INT",
          "propertiesKey": "detection.track.minimum.length"
        },
        {
          "name": "MIN_OVERLAP",
          "description": "In the context of videos, the minimum overlap between detection bounding boxes for adjacent tracks to be considered continuous. When not positive, non-overlapping detections may be combined into one track. When 1, only detections with exact overlap may be combined into one track. When greater than 1, each track will have exactly one detection. Default value is defined by the OpenMPF properties file.",
          "type": "DOUBLE",
          "propertiesKey": "detection.track.overlap.threshold"
        },
        {
          "name": "SEARCH_REGION_ENABLE_DETECTION",
          "description": "Enable cropping.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "SEARCH_REGION_TOP_LEFT_X_DETECTION",
          "description": "X coordinate for top left corner of cropped frame. If negative, 0 will be used.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "SEARCH_REGION_TOP_LEFT_Y_DETECTION",
          "description": "Y coordinate for top left corner of cropped frame. If negative, 0 will be used.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION",
          "description": "X coordinate for bottom right corner of cropped frame. If negative, bottom right X of input media will be used.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION",
          "description": "Y coordinate for bottom right corner of cropped frame. If negative, bottom right Y of input media. will be used.",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "ROTATION",
          "description": "Specifies the number of degrees in the clockwise direction that the media will be rotated. Only 90, 180 and 270 degrees are supported.",
          "type": "INT",
          "defaultValue": "0"
        },
        {
          "name": "HORIZONTAL_FLIP",
          "description": "Specifies whether or not the original media is flipped. Rotation occurs before flipping.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "AUTO_ROTATE",
          "description": "Specifies whether not to rotate media based on EXIF data or video metadata.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "AUTO_FLIP",
          "description": "Specifies whether or not to flip media based on EXIF data.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "MODEL_NAME",
          "description": "Name of Darknet model to run.",
          "type": "STRING",
          "defaultValue": "tiny yolo"
        },
        {
          "name": "MODELS_DIR_PATH",
          "description": "Path to models directory",
          "type": "STRING",
          "propertiesKey": "detection.models.dir.path"
        },
        {
          "name": "USE_PREPROCESSOR",
          "description": "Enables preprocessor mode. If enabled, and multiple Darknet detections in a frame share the same classification, then those are merged into a single detection where the region corresponds to the superset region that encapsulates all of the original detections, and the confidence value is the probability that at least one of the original detections is a true positive. If disabled, multiple Darknet detections in a frame are not merged together.",
          "type": "BOOLEAN",
          "defaultValue": "false"
        },
        {
          "name": "NUMBER_OF_CLASSIFICATIONS_PER_REGION",
          "description": "Only applies if USE_PREPROCESSOR is false. The number of classifications, N, to return for each region. The N highest confidence classifications found by the network per region will be returned with their associated confidence values. The value must be greater than 0. At most, the maximum number of classifications that the model supports will be reported.",
          "type": "INT",
          "defaultValue": "5"
        },
        {
          "name": "CLASS_WHITELIST_FILE",
          "description": "When provided, only class names contained in the specified file will be reported.",
          "type": "STRING",
          "defaultValue": ""
        },
        {
          "name": "CUDA_DEVICE_ID",
          "description": "ID of CUDA device (typically 0) that will be used to run Darknet. When less than 0 CUDA will be disabled.",
          "type": "INT",
          "propertiesKey": "detection.cuda.device.id"
        },
        {
          "name": "FALLBACK_TO_CPU_WHEN_GPU_PROBLEM",
          "description": "Indicates whether or not the CPU only version of Darknet should run if there is an issue with the GPU. Only used when CUDA_DEVICE_ID >= 0.",
          "type": "BOOLEAN",
          "propertiesKey": "detection.use.cpu.when.gpu.problem"
        }
      ]
    }
  },
  "actions": [
    {
      "name": "TINY YOLO OBJECT DETECTION ACTION",
      "description": "Runs the Tiny YOLO object detection Darknet model.",
      "algorithm": "DARKNET",
      "properties": [
        {
          "name": "CONFIDENCE_THRESHOLD",
          "value": "0.5"
        },
        {
          "name": "MODEL_NAME",
          "value": "TINY YOLO"
        }
      ]
    },
    {
      "name": "TINY YOLO OBJECT DETECTION PREPROCESSOR ACTION",
      "description": "Runs the Tiny YOLO object detection Darknet model in preprocessor mode.",
      "algorithm": "DARKNET",
      "properties": [
        {
          "name": "CONFIDENCE_THRESHOLD",
          "value": "0.5"
        },
        {
          "name": "MODEL_NAME",
          "value": "TINY YOLO"
        },
        {
          "name": "USE_PREPROCESSOR",
          "value": "true"
        }
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION ACTION",
      "description": "Runs the YOLO object detection Darknet model.",
      "algorithm": "DARKNET",
      "properties": [
        {
          "name": "CONFIDENCE_THRESHOLD",
          "value": "0.5"
        },
        {
          "name": "MODEL_NAME",
          "value": "YOLO"
        }
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION PREPROCESSOR ACTION",
      "description": "Runs the YOLO object detection Darknet model in preprocessor mode.",
      "algorithm": "DARKNET",
      "properties": [
        {
          "name": "CONFIDENCE_THRESHOLD",
          "value": "0.5"
        },
        {
          "name": "MODEL_NAME",
          "value": "YOLO"
        },
        {
          "name": "USE_PREPROCESSOR",
          "value": "true"
        }
      ]
    }
  ],
  "tasks": [
    {
      "name": "TINY YOLO OBJECT DETECTION TASK",
      "description": "Runs the Tiny YOLO object detection Darknet model.",
      "actions": [
        "TINY YOLO OBJECT DETECTION ACTION"
      ]
    },
    {
      "name": "TINY YOLO OBJECT DETECTION PREPROCESSOR TASK",
      "description": "Runs the Tiny YOLO object detection Darknet model in preprocessor mode.",
      "actions": [
        "TINY YOLO OBJECT DETECTION PREPROCESSOR ACTION"
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION TASK",
      "description": "Runs the YOLO object detection Darknet model.",
      "actions": [
        "YOLO OBJECT DETECTION ACTION"
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION PREPROCESSOR TASK",
      "description": "Runs the YOLO object detection Darknet model in preprocessor mode.",
      "actions": [
        "YOLO OBJECT DETECTION PREPROCESSOR ACTION"
      ]
    }
  ],
  "pipelines": [
    {
      "name": "TINY YOLO OBJECT DETECTION PIPELINE",
      "description": "Runs the Tiny YOLO object detection Darknet model.",
      "tasks": [
        "TINY YOLO OBJECT DETECTION TASK"
      ]
    },
    {
      "name": "TINY YOLO OBJECT DETECTION (WITH MARKUP) PIPELINE",
      "description": "Runs the Tiny YOLO object detection Darknet model and produces markup.",
      "tasks": [
        "TINY YOLO OBJECT DETECTION TASK",
        "OCV GENERIC MARKUP TASK"
      ]
    },
    {
      "name": "TINY YOLO OBJECT DETECTION PREPROCESSOR PIPELINE",
      "description": "Runs the Tiny YOLO object detection Darknet model in preprocessor mode.",
      "tasks": [
        "TINY YOLO OBJECT DETECTION PREPROCESSOR TASK"
      ]
    },
    {
      "name": "TINY YOLO OBJECT DETECTION PREPROCESSOR (WITH MARKUP) PIPELINE",
      "description": "Runs the Tiny YOLO object detection Darknet model in preprocessor mode and produces markup.",
      "tasks": [
        "TINY YOLO OBJECT DETECTION PREPROCESSOR TASK",
        "OCV GENERIC MARKUP TASK"
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION PIPELINE",
      "description": "Runs the YOLO object detection Darknet model.",
      "tasks": [
        "YOLO OBJECT DETECTION TASK"
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION (WITH MARKUP) PIPELINE",
      "description": "Runs the YOLO object detection Darknet model and produces markup.",
      "tasks": [
        "YOLO OBJECT DETECTION TASK",
        "OCV GENERIC MARKUP TASK"
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION PREPROCESSOR PIPELINE",
      "description": "Runs the YOLO object detection Darknet model in preprocessor mode.",
      "tasks": [
        "YOLO OBJECT DETECTION PREPROCESSOR TASK"
      ]
    },
    {
      "name": "YOLO OBJECT DETECTION PREPROCESSOR (WITH MARKUP) PIPELINE",
      "description": "Runs the YOLO object detection Darknet model in preprocessor mode and produces markup.",
      "tasks": [
        "YOLO OBJECT DETECTION PREPROCESSOR TASK",
        "OCV GENERIC MARKUP TASK"
      ]
    }
  ]
}