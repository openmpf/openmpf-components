***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_l14_bestval_ep50.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['TRAINER.COOP.N_CTX', '16', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '1']
output_dir: output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1
resume: 
root: /ckb-nfs/home/zcafego/
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 1
  ROOT: /ckb-nfs/home/zcafego/
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-L/14
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.1.0
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: 10.0.0-4ubuntu1 
CMake version: version 3.16.3
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-166-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA A100-SXM4-40GB
GPU 1: NVIDIA A100-SXM4-40GB
GPU 2: NVIDIA A100-SXM4-40GB
GPU 3: NVIDIA A100-SXM4-40GB

Nvidia driver version: 525.125.06
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.5
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.5
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.5
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.5
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.5
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.5
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.5
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Byte Order:                         Little Endian
Address sizes:                      43 bits physical, 48 bits virtual
CPU(s):                             256
On-line CPU(s) list:                0-255
Thread(s) per core:                 2
Core(s) per socket:                 64
Socket(s):                          2
NUMA node(s):                       2
Vendor ID:                          AuthenticAMD
CPU family:                         23
Model:                              49
Model name:                         AMD EPYC 7H12 64-Core Processor
Stepping:                           0
Frequency boost:                    enabled
CPU MHz:                            1430.454
CPU max MHz:                        2600.0000
CPU min MHz:                        1500.0000
BogoMIPS:                           5200.20
Virtualization:                     AMD-V
L1d cache:                          4 MiB
L1i cache:                          4 MiB
L2 cache:                           64 MiB
L3 cache:                           512 MiB
NUMA node0 CPU(s):                  0-63,128-191
NUMA node1 CPU(s):                  64-127,192-255
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Not affected
Vulnerability Retbleed:             Vulnerable
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca sme sev sev_es

Versions of relevant libraries:
[pip3] flake8==3.7.9
[pip3] numpy==1.24.3
[pip3] torch==2.1.0
[pip3] torchvision==0.8.2
[pip3] triton==2.1.0
[pip3] tritonclient==2.33.0
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               11.8.0               h6a678d5_0  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] libjpeg-turbo             2.0.0                h9bf148f_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46343  
[conda] mkl-service               2.4.0            py38h5eee18b_1  
[conda] mkl_fft                   1.3.8            py38h5eee18b_0  
[conda] mkl_random                1.2.4            py38hdb19cb5_0  
[conda] numpy                     1.24.3           py38hf6e8229_1  
[conda] numpy-base                1.24.3           py38h060ed82_1  
[conda] pytorch                   2.1.0           py3.8_cuda11.8_cudnn8.7.0_0    pytorch
[conda] pytorch-cuda              11.8                 h7e8668a_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchtriton               2.1.0                      py38    pytorch
[conda] torchvision               0.16.0               py38_cu118    pytorch
[conda] triton                    2.1.0                    pypi_0    pypi
        Pillow (10.0.1)

Loading trainer: CoOp
Loading dataset: ImageNet
Loading preprocessed few-shot data from /ckb-nfs/home/zcafego/imagenet/split_fewshot/shot_1-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  1,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-L/14)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Multiple GPUs detected (n_gpus=2), use all of them!
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/tensorboard)
epoch [1/50] batch [5/31] time 0.848 (1.791) data 0.000 (0.242) loss 3.2520 (3.2883) acc 34.3750 (34.3750) lr 1.0000e-05 eta 0:46:07
epoch [1/50] batch [10/31] time 0.899 (1.338) data 0.000 (0.121) loss 3.3301 (3.0773) acc 34.3750 (36.2500) lr 1.0000e-05 eta 0:34:20
epoch [1/50] batch [15/31] time 0.869 (1.184) data 0.000 (0.081) loss 2.5020 (2.8862) acc 46.8750 (40.0000) lr 1.0000e-05 eta 0:30:17
epoch [1/50] batch [20/31] time 0.871 (1.106) data 0.000 (0.061) loss 3.4648 (2.8348) acc 34.3750 (42.0312) lr 1.0000e-05 eta 0:28:11
epoch [1/50] batch [25/31] time 0.895 (1.063) data 0.000 (0.049) loss 2.0664 (2.6439) acc 65.6250 (45.2500) lr 1.0000e-05 eta 0:27:01
epoch [1/50] batch [30/31] time 0.931 (1.036) data 0.000 (0.041) loss 2.5938 (2.5394) acc 43.7500 (46.7708) lr 1.0000e-05 eta 0:26:15
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 32,755
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 63.1%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar
epoch [2/50] batch [5/31] time 0.885 (0.972) data 0.000 (0.146) loss 0.9092 (1.4906) acc 75.0000 (59.3750) lr 2.0000e-03 eta 0:24:31
epoch [2/50] batch [10/31] time 0.866 (0.927) data 0.000 (0.073) loss 1.9473 (1.6865) acc 56.2500 (57.8125) lr 2.0000e-03 eta 0:23:18
epoch [2/50] batch [15/31] time 0.885 (0.911) data 0.000 (0.049) loss 1.6846 (1.6270) acc 59.3750 (61.4583) lr 2.0000e-03 eta 0:22:49
epoch [2/50] batch [20/31] time 0.875 (0.904) data 0.000 (0.037) loss 1.9307 (1.5381) acc 46.8750 (62.8125) lr 2.0000e-03 eta 0:22:34
epoch [2/50] batch [25/31] time 0.899 (0.901) data 0.000 (0.029) loss 1.3008 (1.5084) acc 62.5000 (63.2500) lr 2.0000e-03 eta 0:22:25
epoch [2/50] batch [30/31] time 0.886 (0.903) data 0.000 (0.024) loss 1.5566 (1.4461) acc 65.6250 (64.3750) lr 2.0000e-03 eta 0:22:25
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,297
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 73.7%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar
epoch [3/50] batch [5/31] time 0.896 (0.991) data 0.000 (0.167) loss 0.8872 (1.3119) acc 75.0000 (69.3750) lr 1.9980e-03 eta 0:24:29
epoch [3/50] batch [10/31] time 0.882 (0.938) data 0.000 (0.084) loss 0.8140 (1.2232) acc 71.8750 (70.0000) lr 1.9980e-03 eta 0:23:06
epoch [3/50] batch [15/31] time 0.885 (0.921) data 0.000 (0.056) loss 0.9478 (1.2718) acc 81.2500 (70.2083) lr 1.9980e-03 eta 0:22:36
epoch [3/50] batch [20/31] time 0.880 (0.910) data 0.000 (0.042) loss 1.2627 (1.2977) acc 71.8750 (69.5312) lr 1.9980e-03 eta 0:22:16
epoch [3/50] batch [25/31] time 0.883 (0.907) data 0.000 (0.034) loss 1.1738 (1.3329) acc 68.7500 (68.0000) lr 1.9980e-03 eta 0:22:07
epoch [3/50] batch [30/31] time 0.926 (0.910) data 0.000 (0.028) loss 1.1367 (1.2945) acc 75.0000 (68.3333) lr 1.9980e-03 eta 0:22:06
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,754
* accuracy: 75.5%
* error: 24.5%
* macro_f1: 74.7%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar
epoch [4/50] batch [5/31] time 0.877 (0.994) data 0.000 (0.167) loss 1.6201 (1.1210) acc 62.5000 (71.8750) lr 1.9921e-03 eta 0:24:02
epoch [4/50] batch [10/31] time 0.890 (0.934) data 0.000 (0.083) loss 1.0127 (1.1780) acc 68.7500 (70.3125) lr 1.9921e-03 eta 0:22:32
epoch [4/50] batch [15/31] time 0.862 (0.916) data 0.000 (0.056) loss 1.3008 (1.2424) acc 71.8750 (69.5833) lr 1.9921e-03 eta 0:22:00
epoch [4/50] batch [20/31] time 0.893 (0.908) data 0.000 (0.042) loss 2.1914 (1.2863) acc 53.1250 (69.3750) lr 1.9921e-03 eta 0:21:44
epoch [4/50] batch [25/31] time 0.871 (0.903) data 0.000 (0.034) loss 0.7344 (1.2553) acc 78.1250 (69.7500) lr 1.9921e-03 eta 0:21:32
epoch [4/50] batch [30/31] time 0.897 (0.905) data 0.000 (0.028) loss 1.7480 (1.2998) acc 59.3750 (68.4375) lr 1.9921e-03 eta 0:21:31
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,892
* accuracy: 75.8%
* error: 24.2%
* macro_f1: 75.0%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar
epoch [5/50] batch [5/31] time 0.913 (0.977) data 0.000 (0.148) loss 1.3018 (1.4043) acc 75.0000 (65.6250) lr 1.9823e-03 eta 0:23:08
epoch [5/50] batch [10/31] time 0.901 (0.931) data 0.000 (0.074) loss 0.8940 (1.2365) acc 68.7500 (69.0625) lr 1.9823e-03 eta 0:21:58
epoch [5/50] batch [15/31] time 0.883 (0.913) data 0.000 (0.050) loss 0.9497 (1.2506) acc 68.7500 (69.3750) lr 1.9823e-03 eta 0:21:27
epoch [5/50] batch [20/31] time 0.898 (0.908) data 0.000 (0.037) loss 1.3467 (1.2136) acc 71.8750 (70.4688) lr 1.9823e-03 eta 0:21:16
epoch [5/50] batch [25/31] time 0.891 (0.903) data 0.000 (0.030) loss 1.3174 (1.2354) acc 68.7500 (69.5000) lr 1.9823e-03 eta 0:21:04
epoch [5/50] batch [30/31] time 0.896 (0.900) data 0.000 (0.025) loss 1.9980 (1.2541) acc 59.3750 (69.4792) lr 1.9823e-03 eta 0:20:56
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,790
* accuracy: 75.6%
* error: 24.4%
* macro_f1: 74.8%
epoch [6/50] batch [5/31] time 0.864 (1.052) data 0.000 (0.238) loss 1.2295 (1.1853) acc 65.6250 (72.5000) lr 1.9686e-03 eta 0:24:21
epoch [6/50] batch [10/31] time 0.901 (0.966) data 0.000 (0.119) loss 1.2041 (1.2354) acc 75.0000 (72.1875) lr 1.9686e-03 eta 0:22:17
epoch [6/50] batch [15/31] time 0.899 (0.935) data 0.000 (0.080) loss 1.1943 (1.2196) acc 68.7500 (71.4583) lr 1.9686e-03 eta 0:21:30
epoch [6/50] batch [20/31] time 0.900 (0.924) data 0.000 (0.060) loss 1.2080 (1.2304) acc 59.3750 (70.4688) lr 1.9686e-03 eta 0:21:10
epoch [6/50] batch [25/31] time 0.867 (0.921) data 0.000 (0.048) loss 1.1660 (1.2649) acc 68.7500 (69.0000) lr 1.9686e-03 eta 0:21:02
epoch [6/50] batch [30/31] time 0.875 (0.915) data 0.000 (0.040) loss 1.3740 (1.2754) acc 62.5000 (68.6458) lr 1.9686e-03 eta 0:20:49
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,897
* accuracy: 75.8%
* error: 24.2%
* macro_f1: 75.0%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar
epoch [7/50] batch [5/31] time 0.901 (1.000) data 0.000 (0.178) loss 0.9160 (1.1259) acc 78.1250 (70.6250) lr 1.9511e-03 eta 0:22:38
epoch [7/50] batch [10/31] time 0.887 (0.940) data 0.000 (0.089) loss 1.5439 (1.1247) acc 62.5000 (71.8750) lr 1.9511e-03 eta 0:21:12
epoch [7/50] batch [15/31] time 0.865 (0.917) data 0.000 (0.059) loss 1.6309 (1.1862) acc 65.6250 (71.2500) lr 1.9511e-03 eta 0:20:36
epoch [7/50] batch [20/31] time 0.872 (0.907) data 0.000 (0.045) loss 1.1133 (1.1856) acc 75.0000 (71.2500) lr 1.9511e-03 eta 0:20:18
epoch [7/50] batch [25/31] time 0.891 (0.900) data 0.000 (0.036) loss 1.1533 (1.1518) acc 75.0000 (72.2500) lr 1.9511e-03 eta 0:20:05
epoch [7/50] batch [30/31] time 0.899 (0.899) data 0.000 (0.030) loss 1.0312 (1.1234) acc 75.0000 (71.5625) lr 1.9511e-03 eta 0:19:58
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,737
* accuracy: 75.5%
* error: 24.5%
* macro_f1: 74.7%
epoch [8/50] batch [5/31] time 0.901 (0.991) data 0.000 (0.171) loss 0.8101 (1.0462) acc 75.0000 (70.0000) lr 1.9298e-03 eta 0:21:55
epoch [8/50] batch [10/31] time 0.863 (0.934) data 0.000 (0.086) loss 1.9209 (1.1958) acc 59.3750 (67.8125) lr 1.9298e-03 eta 0:20:35
epoch [8/50] batch [15/31] time 0.903 (0.927) data 0.000 (0.057) loss 1.1016 (1.1840) acc 71.8750 (69.5833) lr 1.9298e-03 eta 0:20:22
epoch [8/50] batch [20/31] time 0.874 (0.916) data 0.000 (0.043) loss 1.0625 (1.1754) acc 75.0000 (70.9375) lr 1.9298e-03 eta 0:20:02
epoch [8/50] batch [25/31] time 0.900 (0.913) data 0.000 (0.035) loss 0.8574 (1.2035) acc 81.2500 (70.7500) lr 1.9298e-03 eta 0:19:53
epoch [8/50] batch [30/31] time 0.872 (0.908) data 0.000 (0.029) loss 1.0049 (1.1626) acc 78.1250 (72.0833) lr 1.9298e-03 eta 0:19:43
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,818
* accuracy: 75.6%
* error: 24.4%
* macro_f1: 74.9%
epoch [9/50] batch [5/31] time 0.899 (0.992) data 0.000 (0.172) loss 1.2334 (1.2978) acc 68.7500 (68.7500) lr 1.9048e-03 eta 0:21:26
epoch [9/50] batch [10/31] time 0.887 (0.934) data 0.000 (0.086) loss 1.2051 (1.1667) acc 65.6250 (70.3125) lr 1.9048e-03 eta 0:20:06
epoch [9/50] batch [15/31] time 0.878 (0.928) data 0.000 (0.058) loss 0.9771 (1.1819) acc 71.8750 (70.2083) lr 1.9048e-03 eta 0:19:54
epoch [9/50] batch [20/31] time 0.890 (0.917) data 0.000 (0.043) loss 1.0518 (1.1873) acc 68.7500 (69.6875) lr 1.9048e-03 eta 0:19:35
epoch [9/50] batch [25/31] time 0.896 (0.915) data 0.000 (0.035) loss 2.2754 (1.2481) acc 59.3750 (69.5000) lr 1.9048e-03 eta 0:19:28
epoch [9/50] batch [30/31] time 0.896 (0.911) data 0.000 (0.029) loss 0.8281 (1.2225) acc 81.2500 (69.8958) lr 1.9048e-03 eta 0:19:18
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,954
* accuracy: 75.9%
* error: 24.1%
* macro_f1: 75.1%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar
epoch [10/50] batch [5/31] time 0.890 (0.996) data 0.000 (0.162) loss 1.6455 (1.1373) acc 65.6250 (75.0000) lr 1.8763e-03 eta 0:21:00
epoch [10/50] batch [10/31] time 0.907 (0.938) data 0.000 (0.081) loss 1.0127 (1.0890) acc 71.8750 (71.5625) lr 1.8763e-03 eta 0:19:43
epoch [10/50] batch [15/31] time 0.884 (0.919) data 0.000 (0.054) loss 0.8979 (1.0939) acc 81.2500 (71.6667) lr 1.8763e-03 eta 0:19:14
epoch [10/50] batch [20/31] time 0.903 (0.917) data 0.000 (0.041) loss 1.3516 (1.1165) acc 65.6250 (70.9375) lr 1.8763e-03 eta 0:19:07
epoch [10/50] batch [25/31] time 0.901 (0.910) data 0.000 (0.033) loss 1.0420 (1.1205) acc 71.8750 (70.7500) lr 1.8763e-03 eta 0:18:53
epoch [10/50] batch [30/31] time 0.881 (0.905) data 0.000 (0.027) loss 1.1924 (1.1153) acc 78.1250 (71.2500) lr 1.8763e-03 eta 0:18:43
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,602
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 74.4%
epoch [11/50] batch [5/31] time 1.061 (1.024) data 0.001 (0.165) loss 1.1670 (0.9580) acc 65.6250 (73.7500) lr 1.8443e-03 eta 0:21:04
epoch [11/50] batch [10/31] time 0.862 (0.947) data 0.000 (0.083) loss 1.1631 (1.0304) acc 71.8750 (72.5000) lr 1.8443e-03 eta 0:19:24
epoch [11/50] batch [15/31] time 0.876 (0.925) data 0.000 (0.055) loss 1.4395 (1.0790) acc 68.7500 (72.0833) lr 1.8443e-03 eta 0:18:53
epoch [11/50] batch [20/31] time 0.878 (0.915) data 0.000 (0.042) loss 1.1328 (1.0555) acc 65.6250 (72.9688) lr 1.8443e-03 eta 0:18:36
epoch [11/50] batch [25/31] time 0.849 (0.909) data 0.001 (0.033) loss 0.9546 (1.0706) acc 75.0000 (72.6250) lr 1.8443e-03 eta 0:18:24
epoch [11/50] batch [30/31] time 0.867 (0.903) data 0.000 (0.028) loss 0.7925 (1.0717) acc 78.1250 (72.9167) lr 1.8443e-03 eta 0:18:12
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,461
* accuracy: 74.9%
* error: 25.1%
* macro_f1: 74.1%
epoch [12/50] batch [5/31] time 0.886 (0.980) data 0.000 (0.159) loss 1.3281 (1.0457) acc 71.8750 (73.1250) lr 1.8090e-03 eta 0:19:40
epoch [12/50] batch [10/31] time 0.887 (0.928) data 0.000 (0.079) loss 1.0742 (1.2715) acc 71.8750 (67.5000) lr 1.8090e-03 eta 0:18:32
epoch [12/50] batch [15/31] time 0.885 (0.914) data 0.000 (0.053) loss 1.4307 (1.2462) acc 68.7500 (69.1667) lr 1.8090e-03 eta 0:18:10
epoch [12/50] batch [20/31] time 0.870 (0.903) data 0.000 (0.040) loss 0.8076 (1.1340) acc 75.0000 (71.8750) lr 1.8090e-03 eta 0:17:53
epoch [12/50] batch [25/31] time 0.865 (0.902) data 0.000 (0.032) loss 0.6460 (1.0852) acc 84.3750 (73.2500) lr 1.8090e-03 eta 0:17:48
epoch [12/50] batch [30/31] time 0.903 (0.900) data 0.000 (0.027) loss 1.6943 (1.0802) acc 65.6250 (73.2292) lr 1.8090e-03 eta 0:17:40
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,538
* accuracy: 75.1%
* error: 24.9%
* macro_f1: 74.3%
epoch [13/50] batch [5/31] time 0.919 (0.991) data 0.001 (0.156) loss 1.1338 (1.1184) acc 68.7500 (71.2500) lr 1.7705e-03 eta 0:19:21
epoch [13/50] batch [10/31] time 0.889 (0.936) data 0.000 (0.078) loss 0.6470 (1.0664) acc 81.2500 (71.2500) lr 1.7705e-03 eta 0:18:13
epoch [13/50] batch [15/31] time 0.889 (0.923) data 0.000 (0.052) loss 1.1631 (1.0973) acc 71.8750 (71.6667) lr 1.7705e-03 eta 0:17:53
epoch [13/50] batch [20/31] time 0.893 (0.913) data 0.000 (0.039) loss 0.8389 (1.0665) acc 78.1250 (72.5000) lr 1.7705e-03 eta 0:17:36
epoch [13/50] batch [25/31] time 0.883 (0.911) data 0.000 (0.031) loss 0.9072 (1.0519) acc 78.1250 (72.8750) lr 1.7705e-03 eta 0:17:30
epoch [13/50] batch [30/31] time 0.885 (0.905) data 0.000 (0.026) loss 1.1982 (1.0227) acc 71.8750 (73.4375) lr 1.7705e-03 eta 0:17:18
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,587
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 74.3%
epoch [14/50] batch [5/31] time 0.861 (0.977) data 0.000 (0.163) loss 0.7578 (1.1274) acc 84.3750 (70.6250) lr 1.7290e-03 eta 0:18:35
epoch [14/50] batch [10/31] time 0.874 (0.931) data 0.000 (0.082) loss 1.5488 (1.0801) acc 75.0000 (75.0000) lr 1.7290e-03 eta 0:17:38
epoch [14/50] batch [15/31] time 0.887 (0.918) data 0.000 (0.055) loss 0.5249 (1.1114) acc 78.1250 (73.9583) lr 1.7290e-03 eta 0:17:18
epoch [14/50] batch [20/31] time 0.882 (0.914) data 0.000 (0.041) loss 1.3955 (1.0959) acc 71.8750 (74.8438) lr 1.7290e-03 eta 0:17:09
epoch [14/50] batch [25/31] time 0.883 (0.908) data 0.000 (0.033) loss 0.8618 (1.0610) acc 71.8750 (74.7500) lr 1.7290e-03 eta 0:16:59
epoch [14/50] batch [30/31] time 0.912 (0.905) data 0.000 (0.028) loss 0.7759 (1.0758) acc 84.3750 (74.4792) lr 1.7290e-03 eta 0:16:50
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,475
* accuracy: 75.0%
* error: 25.0%
* macro_f1: 74.1%
epoch [15/50] batch [5/31] time 0.915 (1.000) data 0.000 (0.164) loss 0.7251 (0.8655) acc 81.2500 (77.5000) lr 1.6845e-03 eta 0:18:30
epoch [15/50] batch [10/31] time 0.893 (0.945) data 0.001 (0.082) loss 0.9185 (0.9269) acc 68.7500 (75.0000) lr 1.6845e-03 eta 0:17:25
epoch [15/50] batch [15/31] time 0.875 (0.922) data 0.000 (0.055) loss 0.9561 (0.9604) acc 75.0000 (74.5833) lr 1.6845e-03 eta 0:16:55
epoch [15/50] batch [20/31] time 0.890 (0.912) data 0.000 (0.041) loss 0.9443 (0.9170) acc 75.0000 (76.2500) lr 1.6845e-03 eta 0:16:39
epoch [15/50] batch [25/31] time 0.886 (0.913) data 0.000 (0.033) loss 1.3262 (0.9984) acc 62.5000 (74.2500) lr 1.6845e-03 eta 0:16:35
epoch [15/50] batch [30/31] time 0.869 (0.906) data 0.000 (0.028) loss 1.2676 (0.9855) acc 62.5000 (74.4792) lr 1.6845e-03 eta 0:16:24
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,534
* accuracy: 75.1%
* error: 24.9%
* macro_f1: 74.2%
epoch [16/50] batch [5/31] time 0.991 (1.001) data 0.000 (0.161) loss 0.5278 (1.1270) acc 81.2500 (71.2500) lr 1.6374e-03 eta 0:18:01
epoch [16/50] batch [10/31] time 0.863 (0.939) data 0.000 (0.081) loss 1.4980 (1.1190) acc 68.7500 (72.1875) lr 1.6374e-03 eta 0:16:49
epoch [16/50] batch [15/31] time 0.864 (0.916) data 0.001 (0.054) loss 1.8232 (1.1531) acc 62.5000 (71.2500) lr 1.6374e-03 eta 0:16:20
epoch [16/50] batch [20/31] time 0.871 (0.906) data 0.000 (0.040) loss 1.6152 (1.1071) acc 65.6250 (72.1875) lr 1.6374e-03 eta 0:16:04
epoch [16/50] batch [25/31] time 0.874 (0.903) data 0.000 (0.032) loss 0.5996 (1.1028) acc 93.7500 (73.5000) lr 1.6374e-03 eta 0:15:57
epoch [16/50] batch [30/31] time 0.882 (0.901) data 0.000 (0.027) loss 1.6787 (1.1273) acc 53.1250 (73.1250) lr 1.6374e-03 eta 0:15:50
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,346
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 73.8%
epoch [17/50] batch [5/31] time 0.895 (0.979) data 0.000 (0.158) loss 0.8472 (0.7923) acc 81.2500 (80.6250) lr 1.5878e-03 eta 0:17:07
epoch [17/50] batch [10/31] time 0.898 (0.928) data 0.001 (0.079) loss 1.0752 (0.8329) acc 75.0000 (78.7500) lr 1.5878e-03 eta 0:16:08
epoch [17/50] batch [15/31] time 0.870 (0.908) data 0.000 (0.053) loss 0.5806 (0.9451) acc 84.3750 (75.8333) lr 1.5878e-03 eta 0:15:43
epoch [17/50] batch [20/31] time 0.863 (0.898) data 0.000 (0.040) loss 1.5801 (1.0469) acc 65.6250 (74.2188) lr 1.5878e-03 eta 0:15:28
epoch [17/50] batch [25/31] time 0.882 (0.896) data 0.000 (0.032) loss 1.4326 (1.0514) acc 62.5000 (73.5000) lr 1.5878e-03 eta 0:15:21
epoch [17/50] batch [30/31] time 0.906 (0.895) data 0.000 (0.027) loss 1.1055 (1.0325) acc 75.0000 (74.4792) lr 1.5878e-03 eta 0:15:16
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,314
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 73.7%
epoch [18/50] batch [5/31] time 0.900 (0.974) data 0.000 (0.153) loss 0.9189 (0.9608) acc 75.0000 (77.5000) lr 1.5358e-03 eta 0:16:31
epoch [18/50] batch [10/31] time 0.887 (0.928) data 0.000 (0.077) loss 0.8589 (0.9020) acc 75.0000 (76.2500) lr 1.5358e-03 eta 0:15:39
epoch [18/50] batch [15/31] time 0.871 (0.916) data 0.000 (0.051) loss 0.7500 (1.0002) acc 84.3750 (76.0417) lr 1.5358e-03 eta 0:15:23
epoch [18/50] batch [20/31] time 0.864 (0.910) data 0.000 (0.039) loss 0.7793 (0.9611) acc 84.3750 (76.5625) lr 1.5358e-03 eta 0:15:12
epoch [18/50] batch [25/31] time 0.878 (0.904) data 0.000 (0.031) loss 0.7368 (0.9603) acc 84.3750 (76.3750) lr 1.5358e-03 eta 0:15:01
epoch [18/50] batch [30/31] time 0.905 (0.906) data 0.000 (0.026) loss 0.4136 (0.9436) acc 90.6250 (76.7708) lr 1.5358e-03 eta 0:15:00
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,238
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.6%
epoch [19/50] batch [5/31] time 0.874 (0.984) data 0.000 (0.165) loss 0.4106 (0.6513) acc 84.3750 (81.8750) lr 1.4818e-03 eta 0:16:10
epoch [19/50] batch [10/31] time 0.855 (0.931) data 0.000 (0.083) loss 0.6143 (0.8867) acc 87.5000 (79.0625) lr 1.4818e-03 eta 0:15:14
epoch [19/50] batch [15/31] time 0.915 (0.917) data 0.000 (0.055) loss 0.8555 (0.8581) acc 81.2500 (79.3750) lr 1.4818e-03 eta 0:14:55
epoch [19/50] batch [20/31] time 0.902 (0.907) data 0.000 (0.042) loss 0.9316 (0.8530) acc 78.1250 (79.6875) lr 1.4818e-03 eta 0:14:41
epoch [19/50] batch [25/31] time 0.903 (0.901) data 0.000 (0.033) loss 1.5664 (0.8866) acc 71.8750 (79.1250) lr 1.4818e-03 eta 0:14:31
epoch [19/50] batch [30/31] time 0.907 (0.904) data 0.000 (0.028) loss 1.3672 (0.9513) acc 71.8750 (77.6042) lr 1.4818e-03 eta 0:14:29
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,016
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 73.1%
epoch [20/50] batch [5/31] time 0.878 (0.993) data 0.000 (0.169) loss 1.0312 (0.7780) acc 78.1250 (83.1250) lr 1.4258e-03 eta 0:15:49
epoch [20/50] batch [10/31] time 0.888 (0.944) data 0.000 (0.085) loss 0.7783 (0.8637) acc 81.2500 (79.0625) lr 1.4258e-03 eta 0:14:57
epoch [20/50] batch [15/31] time 0.870 (0.922) data 0.000 (0.057) loss 1.1758 (0.9426) acc 71.8750 (77.9167) lr 1.4258e-03 eta 0:14:31
epoch [20/50] batch [20/31] time 0.895 (0.911) data 0.000 (0.042) loss 1.1299 (0.9577) acc 78.1250 (76.7188) lr 1.4258e-03 eta 0:14:17
epoch [20/50] batch [25/31] time 0.896 (0.910) data 0.000 (0.034) loss 1.1758 (0.9182) acc 78.1250 (76.5000) lr 1.4258e-03 eta 0:14:11
epoch [20/50] batch [30/31] time 0.895 (0.905) data 0.000 (0.028) loss 1.8887 (0.9336) acc 65.6250 (76.9792) lr 1.4258e-03 eta 0:14:02
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,267
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.7%
epoch [21/50] batch [5/31] time 0.857 (0.975) data 0.000 (0.161) loss 0.9673 (0.7929) acc 78.1250 (81.2500) lr 1.3681e-03 eta 0:15:02
epoch [21/50] batch [10/31] time 0.892 (0.924) data 0.000 (0.081) loss 0.9800 (0.9207) acc 81.2500 (78.1250) lr 1.3681e-03 eta 0:14:09
epoch [21/50] batch [15/31] time 0.859 (0.906) data 0.000 (0.054) loss 0.5186 (0.9623) acc 81.2500 (75.8333) lr 1.3681e-03 eta 0:13:49
epoch [21/50] batch [20/31] time 0.903 (0.899) data 0.000 (0.040) loss 1.1680 (0.9311) acc 75.0000 (76.5625) lr 1.3681e-03 eta 0:13:38
epoch [21/50] batch [25/31] time 0.876 (0.895) data 0.000 (0.032) loss 0.6650 (0.9474) acc 81.2500 (76.5000) lr 1.3681e-03 eta 0:13:30
epoch [21/50] batch [30/31] time 0.901 (0.893) data 0.000 (0.027) loss 0.9966 (0.9209) acc 81.2500 (76.8750) lr 1.3681e-03 eta 0:13:23
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 37,230
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.6%
epoch [22/50] batch [5/31] time 0.876 (0.973) data 0.000 (0.139) loss 1.0537 (1.1194) acc 78.1250 (73.7500) lr 1.3090e-03 eta 0:14:29
epoch [22/50] batch [10/31] time 0.904 (0.929) data 0.000 (0.070) loss 0.5181 (0.9966) acc 87.5000 (76.2500) lr 1.3090e-03 eta 0:13:45
epoch [22/50] batch [15/31] time 0.871 (0.910) data 0.000 (0.047) loss 0.9980 (0.9783) acc 71.8750 (76.2500) lr 1.3090e-03 eta 0:13:23
epoch [22/50] batch [20/31] time 0.868 (0.905) data 0.000 (0.035) loss 0.8818 (0.9543) acc 75.0000 (76.0938) lr 1.3090e-03 eta 0:13:15
epoch [22/50] batch [25/31] time 0.925 (0.901) data 0.000 (0.028) loss 0.5767 (0.9456) acc 75.0000 (75.8750) lr 1.3090e-03 eta 0:13:07
epoch [22/50] batch [30/31] time 0.876 (0.902) data 0.000 (0.023) loss 0.6934 (0.9264) acc 84.3750 (76.3542) lr 1.3090e-03 eta 0:13:04
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,829
* accuracy: 73.7%
* error: 26.3%
* macro_f1: 72.7%
epoch [23/50] batch [5/31] time 0.884 (0.959) data 0.000 (0.148) loss 0.7070 (0.7402) acc 81.2500 (80.6250) lr 1.2487e-03 eta 0:13:47
epoch [23/50] batch [10/31] time 0.893 (0.921) data 0.000 (0.074) loss 1.0254 (0.7157) acc 68.7500 (80.6250) lr 1.2487e-03 eta 0:13:10
epoch [23/50] batch [15/31] time 0.885 (0.911) data 0.000 (0.049) loss 0.6724 (0.7559) acc 84.3750 (80.0000) lr 1.2487e-03 eta 0:12:57
epoch [23/50] batch [20/31] time 0.854 (0.905) data 0.000 (0.037) loss 1.5605 (0.8691) acc 71.8750 (78.7500) lr 1.2487e-03 eta 0:12:47
epoch [23/50] batch [25/31] time 0.899 (0.899) data 0.000 (0.030) loss 0.5332 (0.8755) acc 90.6250 (79.3750) lr 1.2487e-03 eta 0:12:38
epoch [23/50] batch [30/31] time 0.890 (0.896) data 0.000 (0.025) loss 0.8896 (0.8682) acc 78.1250 (79.2708) lr 1.2487e-03 eta 0:12:31
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,940
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 73.0%
epoch [24/50] batch [5/31] time 0.887 (0.964) data 0.000 (0.142) loss 1.0850 (0.9168) acc 71.8750 (76.2500) lr 1.1874e-03 eta 0:13:22
epoch [24/50] batch [10/31] time 0.890 (0.921) data 0.000 (0.071) loss 1.2119 (0.9048) acc 78.1250 (78.1250) lr 1.1874e-03 eta 0:12:41
epoch [24/50] batch [15/31] time 0.899 (0.923) data 0.000 (0.047) loss 0.9634 (0.9310) acc 75.0000 (78.5417) lr 1.1874e-03 eta 0:12:38
epoch [24/50] batch [20/31] time 0.892 (0.911) data 0.000 (0.036) loss 1.0273 (0.9138) acc 68.7500 (78.4375) lr 1.1874e-03 eta 0:12:23
epoch [24/50] batch [25/31] time 0.862 (0.902) data 0.000 (0.029) loss 0.6558 (0.8948) acc 84.3750 (79.2500) lr 1.1874e-03 eta 0:12:12
epoch [24/50] batch [30/31] time 0.861 (0.897) data 0.000 (0.024) loss 1.0312 (0.8881) acc 71.8750 (79.2708) lr 1.1874e-03 eta 0:12:03
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,574
* accuracy: 73.1%
* error: 26.9%
* macro_f1: 72.3%
epoch [25/50] batch [5/31] time 0.899 (0.947) data 0.000 (0.127) loss 0.9048 (0.7045) acc 75.0000 (83.7500) lr 1.1253e-03 eta 0:12:38
epoch [25/50] batch [10/31] time 0.899 (0.917) data 0.000 (0.063) loss 0.9634 (0.7408) acc 87.5000 (85.3125) lr 1.1253e-03 eta 0:12:09
epoch [25/50] batch [15/31] time 0.890 (0.909) data 0.000 (0.042) loss 0.3577 (0.7461) acc 93.7500 (83.5417) lr 1.1253e-03 eta 0:11:58
epoch [25/50] batch [20/31] time 0.914 (0.908) data 0.000 (0.032) loss 1.5703 (0.8438) acc 65.6250 (80.7812) lr 1.1253e-03 eta 0:11:53
epoch [25/50] batch [25/31] time 0.880 (0.903) data 0.000 (0.026) loss 0.6733 (0.8183) acc 81.2500 (80.8750) lr 1.1253e-03 eta 0:11:45
epoch [25/50] batch [30/31] time 0.888 (0.899) data 0.000 (0.021) loss 0.7671 (0.8108) acc 84.3750 (80.7292) lr 1.1253e-03 eta 0:11:37
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,642
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.4%
epoch [26/50] batch [5/31] time 0.852 (0.968) data 0.000 (0.153) loss 0.7314 (0.7089) acc 84.3750 (82.5000) lr 1.0628e-03 eta 0:12:25
epoch [26/50] batch [10/31] time 0.890 (0.923) data 0.000 (0.077) loss 1.0029 (0.7572) acc 81.2500 (81.5625) lr 1.0628e-03 eta 0:11:46
epoch [26/50] batch [15/31] time 0.913 (0.912) data 0.000 (0.051) loss 1.1104 (0.8136) acc 71.8750 (80.8333) lr 1.0628e-03 eta 0:11:32
epoch [26/50] batch [20/31] time 0.878 (0.905) data 0.000 (0.038) loss 1.1436 (0.8682) acc 71.8750 (79.5312) lr 1.0628e-03 eta 0:11:23
epoch [26/50] batch [25/31] time 0.890 (0.901) data 0.000 (0.031) loss 0.5210 (0.8599) acc 90.6250 (79.8750) lr 1.0628e-03 eta 0:11:15
epoch [26/50] batch [30/31] time 0.891 (0.900) data 0.000 (0.026) loss 0.9912 (0.8883) acc 87.5000 (79.3750) lr 1.0628e-03 eta 0:11:10
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,661
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.4%
epoch [27/50] batch [5/31] time 0.866 (0.964) data 0.000 (0.148) loss 0.8613 (0.8125) acc 87.5000 (80.6250) lr 1.0000e-03 eta 0:11:52
epoch [27/50] batch [10/31] time 0.892 (0.927) data 0.000 (0.074) loss 1.7266 (1.0006) acc 71.8750 (78.1250) lr 1.0000e-03 eta 0:11:20
epoch [27/50] batch [15/31] time 0.894 (0.912) data 0.000 (0.050) loss 0.8267 (0.9043) acc 78.1250 (79.1667) lr 1.0000e-03 eta 0:11:04
epoch [27/50] batch [20/31] time 0.869 (0.905) data 0.000 (0.037) loss 0.6045 (0.8684) acc 84.3750 (78.9062) lr 1.0000e-03 eta 0:10:55
epoch [27/50] batch [25/31] time 0.887 (0.902) data 0.000 (0.030) loss 0.7900 (0.8614) acc 78.1250 (79.2500) lr 1.0000e-03 eta 0:10:48
epoch [27/50] batch [30/31] time 0.878 (0.901) data 0.000 (0.025) loss 1.1357 (0.8957) acc 75.0000 (78.5417) lr 1.0000e-03 eta 0:10:43
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,591
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 72.2%
epoch [28/50] batch [5/31] time 0.853 (0.937) data 0.000 (0.126) loss 0.4980 (0.7694) acc 90.6250 (83.7500) lr 9.3721e-04 eta 0:11:03
epoch [28/50] batch [10/31] time 0.897 (0.911) data 0.000 (0.063) loss 0.4756 (0.6876) acc 87.5000 (84.3750) lr 9.3721e-04 eta 0:10:40
epoch [28/50] batch [15/31] time 0.874 (0.903) data 0.000 (0.042) loss 0.5723 (0.7086) acc 87.5000 (84.3750) lr 9.3721e-04 eta 0:10:30
epoch [28/50] batch [20/31] time 0.995 (0.908) data 0.000 (0.032) loss 0.7671 (0.7512) acc 81.2500 (83.4375) lr 9.3721e-04 eta 0:10:29
epoch [28/50] batch [25/31] time 0.882 (0.903) data 0.000 (0.025) loss 0.6748 (0.7650) acc 81.2500 (83.1250) lr 9.3721e-04 eta 0:10:21
epoch [28/50] batch [30/31] time 0.884 (0.902) data 0.000 (0.021) loss 1.1475 (0.7948) acc 75.0000 (81.7708) lr 9.3721e-04 eta 0:10:15
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,734
* accuracy: 73.5%
* error: 26.5%
* macro_f1: 72.5%
epoch [29/50] batch [5/31] time 0.874 (0.943) data 0.000 (0.124) loss 0.9292 (0.6433) acc 84.3750 (85.0000) lr 8.7467e-04 eta 0:10:38
epoch [29/50] batch [10/31] time 0.874 (0.909) data 0.000 (0.062) loss 1.0020 (0.6859) acc 78.1250 (82.8125) lr 8.7467e-04 eta 0:10:10
epoch [29/50] batch [15/31] time 0.864 (0.899) data 0.000 (0.042) loss 0.6758 (0.6638) acc 87.5000 (83.7500) lr 8.7467e-04 eta 0:09:59
epoch [29/50] batch [20/31] time 1.019 (0.900) data 0.000 (0.031) loss 0.5283 (0.6947) acc 87.5000 (82.5000) lr 8.7467e-04 eta 0:09:55
epoch [29/50] batch [25/31] time 0.859 (0.897) data 0.000 (0.025) loss 1.1602 (0.7583) acc 78.1250 (81.6250) lr 8.7467e-04 eta 0:09:49
epoch [29/50] batch [30/31] time 0.888 (0.896) data 0.000 (0.021) loss 1.0537 (0.8103) acc 71.8750 (79.7917) lr 8.7467e-04 eta 0:09:44
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,891
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 72.9%
epoch [30/50] batch [5/31] time 0.872 (0.933) data 0.000 (0.125) loss 0.8848 (0.7889) acc 78.1250 (80.0000) lr 8.1262e-04 eta 0:10:02
epoch [30/50] batch [10/31] time 0.883 (0.913) data 0.000 (0.062) loss 0.4763 (0.7708) acc 84.3750 (81.2500) lr 8.1262e-04 eta 0:09:45
epoch [30/50] batch [15/31] time 0.874 (0.906) data 0.000 (0.042) loss 0.6533 (0.7874) acc 84.3750 (81.2500) lr 8.1262e-04 eta 0:09:36
epoch [30/50] batch [20/31] time 0.888 (0.900) data 0.000 (0.031) loss 0.7061 (0.8078) acc 81.2500 (80.3125) lr 8.1262e-04 eta 0:09:27
epoch [30/50] batch [25/31] time 0.897 (0.901) data 0.000 (0.025) loss 0.6118 (0.8065) acc 78.1250 (79.8750) lr 8.1262e-04 eta 0:09:23
epoch [30/50] batch [30/31] time 0.894 (0.898) data 0.000 (0.021) loss 1.1455 (0.7940) acc 71.8750 (80.5208) lr 8.1262e-04 eta 0:09:17
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,480
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 72.0%
epoch [31/50] batch [5/31] time 0.903 (0.951) data 0.000 (0.129) loss 0.8081 (0.8092) acc 81.2500 (80.0000) lr 7.5131e-04 eta 0:09:44
epoch [31/50] batch [10/31] time 0.838 (0.912) data 0.000 (0.065) loss 0.6001 (0.6951) acc 81.2500 (82.5000) lr 7.5131e-04 eta 0:09:16
epoch [31/50] batch [15/31] time 0.851 (0.896) data 0.000 (0.043) loss 0.5635 (0.7180) acc 90.6250 (82.5000) lr 7.5131e-04 eta 0:09:02
epoch [31/50] batch [20/31] time 0.916 (0.892) data 0.000 (0.033) loss 1.0459 (0.8187) acc 71.8750 (80.3125) lr 7.5131e-04 eta 0:08:55
epoch [31/50] batch [25/31] time 0.877 (0.889) data 0.000 (0.026) loss 1.0596 (0.8350) acc 81.2500 (80.1250) lr 7.5131e-04 eta 0:08:49
epoch [31/50] batch [30/31] time 0.897 (0.889) data 0.000 (0.022) loss 1.1309 (0.8236) acc 71.8750 (80.1042) lr 7.5131e-04 eta 0:08:44
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,526
* accuracy: 73.1%
* error: 26.9%
* macro_f1: 72.1%
epoch [32/50] batch [5/31] time 0.865 (0.941) data 0.000 (0.125) loss 0.9263 (0.8586) acc 81.2500 (81.2500) lr 6.9098e-04 eta 0:09:09
epoch [32/50] batch [10/31] time 0.866 (0.905) data 0.000 (0.063) loss 0.6821 (0.7995) acc 87.5000 (80.6250) lr 6.9098e-04 eta 0:08:43
epoch [32/50] batch [15/31] time 0.881 (0.898) data 0.000 (0.042) loss 0.8745 (0.7245) acc 78.1250 (81.4583) lr 6.9098e-04 eta 0:08:35
epoch [32/50] batch [20/31] time 0.889 (0.893) data 0.000 (0.031) loss 1.3037 (0.7803) acc 78.1250 (80.9375) lr 6.9098e-04 eta 0:08:28
epoch [32/50] batch [25/31] time 0.879 (0.891) data 0.000 (0.025) loss 1.2012 (0.7804) acc 78.1250 (80.8750) lr 6.9098e-04 eta 0:08:22
epoch [32/50] batch [30/31] time 0.896 (0.891) data 0.000 (0.021) loss 0.3354 (0.7622) acc 90.6250 (81.5625) lr 6.9098e-04 eta 0:08:18
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,195
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.4%
epoch [33/50] batch [5/31] time 0.875 (0.951) data 0.000 (0.133) loss 0.7554 (0.8025) acc 90.6250 (82.5000) lr 6.3188e-04 eta 0:08:45
epoch [33/50] batch [10/31] time 0.876 (0.917) data 0.000 (0.067) loss 1.0215 (0.7839) acc 78.1250 (82.1875) lr 6.3188e-04 eta 0:08:22
epoch [33/50] batch [15/31] time 0.897 (0.908) data 0.000 (0.045) loss 0.4202 (0.7574) acc 93.7500 (82.5000) lr 6.3188e-04 eta 0:08:13
epoch [33/50] batch [20/31] time 0.891 (0.902) data 0.000 (0.033) loss 0.7334 (0.7677) acc 81.2500 (82.5000) lr 6.3188e-04 eta 0:08:05
epoch [33/50] batch [25/31] time 0.883 (0.900) data 0.000 (0.027) loss 0.6753 (0.7981) acc 78.1250 (81.8750) lr 6.3188e-04 eta 0:07:59
epoch [33/50] batch [30/31] time 0.922 (0.899) data 0.000 (0.022) loss 0.3496 (0.7874) acc 93.7500 (82.1875) lr 6.3188e-04 eta 0:07:54
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,442
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 71.9%
epoch [34/50] batch [5/31] time 0.909 (0.952) data 0.000 (0.126) loss 0.8091 (0.7973) acc 78.1250 (81.2500) lr 5.7422e-04 eta 0:08:16
epoch [34/50] batch [10/31] time 0.865 (0.914) data 0.001 (0.063) loss 0.3713 (0.7604) acc 93.7500 (84.0625) lr 5.7422e-04 eta 0:07:52
epoch [34/50] batch [15/31] time 0.883 (0.903) data 0.000 (0.042) loss 0.5874 (0.7395) acc 90.6250 (85.0000) lr 5.7422e-04 eta 0:07:42
epoch [34/50] batch [20/31] time 0.873 (0.895) data 0.000 (0.032) loss 0.9878 (0.7862) acc 68.7500 (81.8750) lr 5.7422e-04 eta 0:07:33
epoch [34/50] batch [25/31] time 0.867 (0.892) data 0.000 (0.025) loss 0.9385 (0.8404) acc 78.1250 (80.7500) lr 5.7422e-04 eta 0:07:27
epoch [34/50] batch [30/31] time 0.896 (0.891) data 0.000 (0.021) loss 0.3950 (0.8458) acc 90.6250 (80.9375) lr 5.7422e-04 eta 0:07:22
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,081
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 71.1%
epoch [35/50] batch [5/31] time 0.884 (0.945) data 0.000 (0.125) loss 0.8594 (0.7630) acc 71.8750 (79.3750) lr 5.1825e-04 eta 0:07:44
epoch [35/50] batch [10/31] time 0.879 (0.915) data 0.000 (0.063) loss 1.2666 (0.8583) acc 75.0000 (79.0625) lr 5.1825e-04 eta 0:07:24
epoch [35/50] batch [15/31] time 0.876 (0.906) data 0.000 (0.042) loss 0.8184 (0.8342) acc 68.7500 (79.1667) lr 5.1825e-04 eta 0:07:15
epoch [35/50] batch [20/31] time 0.868 (0.902) data 0.000 (0.031) loss 0.8721 (0.8096) acc 75.0000 (79.6875) lr 5.1825e-04 eta 0:07:09
epoch [35/50] batch [25/31] time 0.879 (0.895) data 0.000 (0.025) loss 0.7129 (0.8309) acc 81.2500 (79.7500) lr 5.1825e-04 eta 0:07:01
epoch [35/50] batch [30/31] time 0.890 (0.897) data 0.000 (0.021) loss 0.6582 (0.7817) acc 78.1250 (80.8333) lr 5.1825e-04 eta 0:06:57
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,549
* accuracy: 73.1%
* error: 26.9%
* macro_f1: 72.2%
epoch [36/50] batch [5/31] time 0.899 (0.953) data 0.000 (0.126) loss 0.9160 (0.8711) acc 81.2500 (81.2500) lr 4.6417e-04 eta 0:07:18
epoch [36/50] batch [10/31] time 0.887 (0.917) data 0.000 (0.063) loss 0.4429 (0.7086) acc 87.5000 (83.7500) lr 4.6417e-04 eta 0:06:57
epoch [36/50] batch [15/31] time 0.899 (0.909) data 0.001 (0.042) loss 0.9619 (0.7028) acc 81.2500 (84.1667) lr 4.6417e-04 eta 0:06:48
epoch [36/50] batch [20/31] time 0.867 (0.901) data 0.000 (0.032) loss 0.7266 (0.7189) acc 90.6250 (84.5312) lr 4.6417e-04 eta 0:06:40
epoch [36/50] batch [25/31] time 0.869 (0.896) data 0.000 (0.025) loss 0.6006 (0.7236) acc 84.3750 (84.5000) lr 4.6417e-04 eta 0:06:34
epoch [36/50] batch [30/31] time 0.870 (0.895) data 0.000 (0.021) loss 0.9199 (0.7367) acc 87.5000 (84.1667) lr 4.6417e-04 eta 0:06:29
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,246
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 71.6%
epoch [37/50] batch [5/31] time 0.890 (0.945) data 0.000 (0.128) loss 1.0371 (0.7881) acc 75.0000 (85.0000) lr 4.1221e-04 eta 0:06:45
epoch [37/50] batch [10/31] time 0.884 (0.912) data 0.000 (0.064) loss 0.7739 (0.8287) acc 90.6250 (83.4375) lr 4.1221e-04 eta 0:06:26
epoch [37/50] batch [15/31] time 0.886 (0.900) data 0.000 (0.043) loss 0.4636 (0.7892) acc 84.3750 (82.0833) lr 4.1221e-04 eta 0:06:17
epoch [37/50] batch [20/31] time 0.878 (0.899) data 0.000 (0.032) loss 0.4536 (0.7667) acc 87.5000 (82.6562) lr 4.1221e-04 eta 0:06:12
epoch [37/50] batch [25/31] time 0.886 (0.896) data 0.000 (0.026) loss 1.1055 (0.7564) acc 71.8750 (82.2500) lr 4.1221e-04 eta 0:06:06
epoch [37/50] batch [30/31] time 0.888 (0.893) data 0.000 (0.021) loss 0.7217 (0.8151) acc 84.3750 (80.9375) lr 4.1221e-04 eta 0:06:00
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,454
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 71.9%
epoch [38/50] batch [5/31] time 0.879 (0.934) data 0.000 (0.124) loss 0.6040 (0.7356) acc 84.3750 (80.0000) lr 3.6258e-04 eta 0:06:11
epoch [38/50] batch [10/31] time 0.872 (0.902) data 0.000 (0.062) loss 1.0137 (0.7932) acc 81.2500 (80.9375) lr 3.6258e-04 eta 0:05:54
epoch [38/50] batch [15/31] time 0.881 (0.892) data 0.000 (0.041) loss 0.9155 (0.7434) acc 75.0000 (82.0833) lr 3.6258e-04 eta 0:05:46
epoch [38/50] batch [20/31] time 0.887 (0.891) data 0.000 (0.031) loss 0.6274 (0.7214) acc 78.1250 (82.0312) lr 3.6258e-04 eta 0:05:41
epoch [38/50] batch [25/31] time 0.884 (0.892) data 0.000 (0.025) loss 0.5835 (0.7103) acc 87.5000 (82.1250) lr 3.6258e-04 eta 0:05:37
epoch [38/50] batch [30/31] time 0.897 (0.890) data 0.000 (0.021) loss 0.5225 (0.7035) acc 81.2500 (82.2917) lr 3.6258e-04 eta 0:05:31
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,287
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 71.6%
epoch [39/50] batch [5/31] time 0.895 (0.956) data 0.000 (0.130) loss 1.1689 (0.9846) acc 75.0000 (80.0000) lr 3.1545e-04 eta 0:05:50
epoch [39/50] batch [10/31] time 0.862 (0.920) data 0.000 (0.065) loss 0.4626 (0.8553) acc 84.3750 (80.6250) lr 3.1545e-04 eta 0:05:33
epoch [39/50] batch [15/31] time 0.876 (0.906) data 0.000 (0.044) loss 0.7241 (0.8632) acc 81.2500 (80.0000) lr 3.1545e-04 eta 0:05:23
epoch [39/50] batch [20/31] time 0.872 (0.900) data 0.000 (0.033) loss 0.7754 (0.8133) acc 78.1250 (81.0938) lr 3.1545e-04 eta 0:05:16
epoch [39/50] batch [25/31] time 0.861 (0.894) data 0.000 (0.026) loss 0.5146 (0.7546) acc 84.3750 (82.2500) lr 3.1545e-04 eta 0:05:10
epoch [39/50] batch [30/31] time 0.881 (0.890) data 0.000 (0.022) loss 0.6841 (0.7965) acc 84.3750 (82.0833) lr 3.1545e-04 eta 0:05:04
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,233
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 71.5%
epoch [40/50] batch [5/31] time 0.884 (0.961) data 0.000 (0.137) loss 0.4541 (0.9224) acc 90.6250 (82.5000) lr 2.7103e-04 eta 0:05:22
epoch [40/50] batch [10/31] time 0.824 (0.914) data 0.000 (0.069) loss 1.0537 (0.8170) acc 71.8750 (82.5000) lr 2.7103e-04 eta 0:05:02
epoch [40/50] batch [15/31] time 0.887 (0.915) data 0.000 (0.046) loss 1.0127 (0.8457) acc 87.5000 (81.6667) lr 2.7103e-04 eta 0:04:58
epoch [40/50] batch [20/31] time 0.853 (0.907) data 0.000 (0.034) loss 0.5474 (0.8309) acc 81.2500 (81.8750) lr 2.7103e-04 eta 0:04:51
epoch [40/50] batch [25/31] time 0.892 (0.901) data 0.000 (0.028) loss 0.9248 (0.8136) acc 75.0000 (81.8750) lr 2.7103e-04 eta 0:04:44
epoch [40/50] batch [30/31] time 0.902 (0.898) data 0.000 (0.023) loss 0.5820 (0.8336) acc 81.2500 (81.5625) lr 2.7103e-04 eta 0:04:39
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,138
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 71.3%
epoch [41/50] batch [5/31] time 0.895 (0.957) data 0.000 (0.138) loss 0.4866 (0.7594) acc 75.0000 (80.0000) lr 2.2949e-04 eta 0:04:51
epoch [41/50] batch [10/31] time 0.911 (0.921) data 0.000 (0.069) loss 0.7866 (0.7962) acc 78.1250 (79.3750) lr 2.2949e-04 eta 0:04:36
epoch [41/50] batch [15/31] time 1.021 (0.918) data 0.000 (0.046) loss 0.4351 (0.7328) acc 87.5000 (81.2500) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [20/31] time 0.868 (0.907) data 0.000 (0.035) loss 0.4490 (0.7153) acc 84.3750 (81.7188) lr 2.2949e-04 eta 0:04:23
epoch [41/50] batch [25/31] time 0.863 (0.899) data 0.000 (0.028) loss 1.2910 (0.7311) acc 75.0000 (82.0000) lr 2.2949e-04 eta 0:04:16
epoch [41/50] batch [30/31] time 0.884 (0.896) data 0.000 (0.023) loss 0.5405 (0.7297) acc 78.1250 (81.7708) lr 2.2949e-04 eta 0:04:10
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,407
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 71.9%
epoch [42/50] batch [5/31] time 0.889 (0.956) data 0.000 (0.134) loss 1.4990 (0.6764) acc 78.1250 (85.6250) lr 1.9098e-04 eta 0:04:21
epoch [42/50] batch [10/31] time 0.892 (0.918) data 0.000 (0.067) loss 1.0273 (0.7518) acc 71.8750 (83.1250) lr 1.9098e-04 eta 0:04:06
epoch [42/50] batch [15/31] time 0.855 (0.901) data 0.000 (0.045) loss 0.7070 (0.7337) acc 84.3750 (83.9583) lr 1.9098e-04 eta 0:03:57
epoch [42/50] batch [20/31] time 0.903 (0.906) data 0.000 (0.034) loss 0.6357 (0.7522) acc 81.2500 (83.4375) lr 1.9098e-04 eta 0:03:54
epoch [42/50] batch [25/31] time 0.900 (0.903) data 0.000 (0.027) loss 0.8120 (0.7550) acc 84.3750 (83.0000) lr 1.9098e-04 eta 0:03:49
epoch [42/50] batch [30/31] time 0.863 (0.897) data 0.000 (0.023) loss 0.9238 (0.7382) acc 75.0000 (83.0208) lr 1.9098e-04 eta 0:03:43
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,267
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 71.6%
epoch [43/50] batch [5/31] time 0.877 (0.956) data 0.000 (0.135) loss 0.5815 (0.6160) acc 78.1250 (85.6250) lr 1.5567e-04 eta 0:03:52
epoch [43/50] batch [10/31] time 0.891 (0.916) data 0.000 (0.068) loss 0.4097 (0.7043) acc 93.7500 (84.6875) lr 1.5567e-04 eta 0:03:38
epoch [43/50] batch [15/31] time 0.871 (0.902) data 0.000 (0.045) loss 0.7144 (0.7178) acc 78.1250 (84.7917) lr 1.5567e-04 eta 0:03:30
epoch [43/50] batch [20/31] time 0.909 (0.898) data 0.000 (0.034) loss 1.0322 (0.7757) acc 71.8750 (83.1250) lr 1.5567e-04 eta 0:03:24
epoch [43/50] batch [25/31] time 0.873 (0.895) data 0.000 (0.027) loss 0.8765 (0.7872) acc 81.2500 (82.2500) lr 1.5567e-04 eta 0:03:19
epoch [43/50] batch [30/31] time 0.899 (0.896) data 0.000 (0.023) loss 0.6226 (0.7641) acc 84.3750 (82.7083) lr 1.5567e-04 eta 0:03:15
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,346
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 71.7%
epoch [44/50] batch [5/31] time 0.850 (0.937) data 0.000 (0.132) loss 0.9893 (0.7952) acc 78.1250 (84.3750) lr 1.2369e-04 eta 0:03:18
epoch [44/50] batch [10/31] time 0.884 (0.911) data 0.000 (0.066) loss 0.7588 (0.7323) acc 84.3750 (84.6875) lr 1.2369e-04 eta 0:03:08
epoch [44/50] batch [15/31] time 0.860 (0.902) data 0.000 (0.044) loss 0.4165 (0.6868) acc 90.6250 (84.7917) lr 1.2369e-04 eta 0:03:02
epoch [44/50] batch [20/31] time 0.883 (0.894) data 0.000 (0.033) loss 0.5518 (0.6486) acc 87.5000 (85.9375) lr 1.2369e-04 eta 0:02:56
epoch [44/50] batch [25/31] time 0.887 (0.898) data 0.000 (0.027) loss 0.7373 (0.6835) acc 81.2500 (84.8750) lr 1.2369e-04 eta 0:02:52
epoch [44/50] batch [30/31] time 0.863 (0.894) data 0.000 (0.022) loss 0.6978 (0.7043) acc 84.3750 (84.4792) lr 1.2369e-04 eta 0:02:47
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,243
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 71.5%
epoch [45/50] batch [5/31] time 0.890 (0.953) data 0.000 (0.129) loss 0.4839 (0.6955) acc 84.3750 (83.1250) lr 9.5173e-05 eta 0:02:52
epoch [45/50] batch [10/31] time 0.897 (0.917) data 0.000 (0.065) loss 0.5420 (0.6375) acc 87.5000 (84.6875) lr 9.5173e-05 eta 0:02:41
epoch [45/50] batch [15/31] time 0.896 (0.912) data 0.000 (0.043) loss 1.1738 (0.6360) acc 81.2500 (85.6250) lr 9.5173e-05 eta 0:02:35
epoch [45/50] batch [20/31] time 0.891 (0.906) data 0.000 (0.032) loss 1.3369 (0.7331) acc 71.8750 (84.0625) lr 9.5173e-05 eta 0:02:30
epoch [45/50] batch [25/31] time 0.874 (0.906) data 0.000 (0.026) loss 0.7939 (0.7171) acc 84.3750 (84.3750) lr 9.5173e-05 eta 0:02:25
epoch [45/50] batch [30/31] time 0.897 (0.902) data 0.000 (0.022) loss 0.7041 (0.7388) acc 75.0000 (83.8542) lr 9.5173e-05 eta 0:02:20
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,191
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.4%
epoch [46/50] batch [5/31] time 0.886 (0.942) data 0.000 (0.125) loss 0.7671 (0.7390) acc 78.1250 (82.5000) lr 7.0224e-05 eta 0:02:21
epoch [46/50] batch [10/31] time 0.845 (0.908) data 0.000 (0.062) loss 0.7671 (0.6531) acc 87.5000 (85.3125) lr 7.0224e-05 eta 0:02:11
epoch [46/50] batch [15/31] time 0.904 (0.904) data 0.000 (0.042) loss 0.4719 (0.6451) acc 87.5000 (85.4167) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [20/31] time 0.915 (0.903) data 0.000 (0.031) loss 0.6128 (0.7030) acc 84.3750 (84.3750) lr 7.0224e-05 eta 0:02:01
epoch [46/50] batch [25/31] time 0.888 (0.904) data 0.000 (0.025) loss 0.6978 (0.6804) acc 81.2500 (85.1250) lr 7.0224e-05 eta 0:01:57
epoch [46/50] batch [30/31] time 0.904 (0.901) data 0.000 (0.021) loss 0.7441 (0.7001) acc 81.2500 (84.4792) lr 7.0224e-05 eta 0:01:52
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,173
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 71.4%
epoch [47/50] batch [5/31] time 0.890 (0.946) data 0.000 (0.120) loss 0.9536 (0.7832) acc 71.8750 (81.2500) lr 4.8943e-05 eta 0:01:52
epoch [47/50] batch [10/31] time 0.871 (0.915) data 0.000 (0.060) loss 0.7979 (0.6747) acc 75.0000 (83.1250) lr 4.8943e-05 eta 0:01:44
epoch [47/50] batch [15/31] time 0.893 (0.903) data 0.000 (0.040) loss 1.1982 (0.6806) acc 84.3750 (84.3750) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [20/31] time 0.865 (0.894) data 0.000 (0.030) loss 0.4045 (0.6634) acc 81.2500 (84.2188) lr 4.8943e-05 eta 0:01:32
epoch [47/50] batch [25/31] time 0.915 (0.892) data 0.000 (0.024) loss 0.4897 (0.6641) acc 93.7500 (84.2500) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [30/31] time 0.852 (0.888) data 0.000 (0.020) loss 0.5640 (0.6782) acc 93.7500 (84.4792) lr 4.8943e-05 eta 0:01:23
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,200
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.5%
epoch [48/50] batch [5/31] time 0.871 (0.949) data 0.001 (0.133) loss 0.6396 (0.7861) acc 93.7500 (86.2500) lr 3.1417e-05 eta 0:01:23
epoch [48/50] batch [10/31] time 0.887 (0.922) data 0.000 (0.067) loss 1.0273 (0.7704) acc 75.0000 (85.0000) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [15/31] time 0.939 (0.915) data 0.000 (0.045) loss 0.4082 (0.7391) acc 96.8750 (85.0000) lr 3.1417e-05 eta 0:01:11
epoch [48/50] batch [20/31] time 0.892 (0.905) data 0.000 (0.033) loss 0.4800 (0.6923) acc 90.6250 (85.0000) lr 3.1417e-05 eta 0:01:06
epoch [48/50] batch [25/31] time 0.899 (0.901) data 0.000 (0.027) loss 0.4441 (0.6702) acc 90.6250 (85.3750) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [30/31] time 0.889 (0.902) data 0.000 (0.022) loss 0.9199 (0.7315) acc 75.0000 (83.5417) lr 3.1417e-05 eta 0:00:56
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,195
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.4%
epoch [49/50] batch [5/31] time 0.851 (0.930) data 0.000 (0.123) loss 0.8584 (0.6711) acc 78.1250 (76.8750) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [10/31] time 0.888 (0.921) data 0.000 (0.062) loss 0.3171 (0.6027) acc 87.5000 (80.9375) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [15/31] time 0.892 (0.908) data 0.000 (0.041) loss 0.9678 (0.6439) acc 84.3750 (81.6667) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [20/31] time 0.864 (0.903) data 0.000 (0.031) loss 0.7812 (0.6873) acc 84.3750 (82.3438) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [25/31] time 0.930 (0.902) data 0.000 (0.025) loss 0.4753 (0.6559) acc 93.7500 (83.0000) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [30/31] time 0.886 (0.899) data 0.000 (0.021) loss 0.5386 (0.6223) acc 84.3750 (83.6458) lr 1.7713e-05 eta 0:00:28
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,191
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.4%
epoch [50/50] batch [5/31] time 0.860 (0.936) data 0.000 (0.126) loss 0.7983 (0.7974) acc 78.1250 (81.2500) lr 7.8853e-06 eta 0:00:24
epoch [50/50] batch [10/31] time 0.884 (0.905) data 0.000 (0.063) loss 0.4873 (0.6901) acc 93.7500 (84.0625) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [15/31] time 0.878 (0.896) data 0.000 (0.042) loss 0.4387 (0.6778) acc 87.5000 (85.2083) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [20/31] time 0.875 (0.894) data 0.000 (0.032) loss 0.4661 (0.7057) acc 87.5000 (84.8438) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [25/31] time 0.892 (0.893) data 0.000 (0.025) loss 1.0576 (0.7488) acc 75.0000 (84.0000) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [30/31] time 0.884 (0.892) data 0.000 (0.021) loss 0.8081 (0.7657) acc 78.1250 (83.5417) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 50,000
* correct: 36,194
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.4%
Checkpoint saved to output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/imagenet/CoOp/vit_l14_bestval_ep50_1shots/nctx16_cscFalse_ctpend/seed1/prompt_learner/model-best.pth.tar" (epoch = 9)
Evaluate on the *test* set
=> result
* total: 50,000
* correct: 37,953
* accuracy: 75.9%
* error: 24.1%
* macro_f1: 75.1%
Elapsed: 2:51:12
